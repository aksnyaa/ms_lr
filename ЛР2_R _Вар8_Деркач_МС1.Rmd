---
title: "ЛР2_R _Вар8_Деркач_МС1"
author: "Деркач Аксинья"
date: "2024-12-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Раздел 2. Проверка гипотез

### Импорт данных для работы

Для начала работы импортируем необходимые данные.
Для этого устанавливаем пакет rio, импортируем файл и выбераем необходимый столбец:

```{r}
library('rio')
dataframe <- import('Данные по вариантам для выполнения типового расчета.xlsx') 
data <- dataframe['v8']
```

Избавимся от последнего текстового значения, а также поменяем тип данных.

```{r}
data <- data[1:100,]
data <- as.data.frame(as.numeric(data)) 
```

Переименуем исследуемый столбец следующим образом:

```{r}
names(data) <- 'Коэффициент финансового левериджа' 
```

Проверим структуру исправленных данных:

```{r}
str(data)
```

Всё верно, можем приступать к проверке гипотез.

### 2.1. Тесты на однородность дисперсий независимых выборок

Для проверки двух выборок на нормальное распределение, создадим две переменные  $X$ и $Y$, где $X$ - первые $50$ наблюдений выборки, а $Y$ – последние $50$ наблюдений при заданном уровне значимости $\alpha$ = 0.05:

```{r}
alpha <- 0.05 #уровень значимости a
x <- data[1:50,] # отрезает в data первые 50 наблюдений
y <- data[51:100,] # отрезает в data вторые 50 наблюдений
```

Для проведения данного теста при оговоренных допущениях используется F-статистика Фишера. По умолчанию встренный тест var.test проводится для двусторонней критической области, но для теста Фишера используется правосторонняя критическая область. Поэтому необходимо указать в качестве аргумента функции как alternative = "greater":

```{r}
var.test(x,y, alternative = "greater")
```

Пронализируем результаты теста:
$F_{наблюдаемое}$ = 0.61399
$p-value$ = 0.9545

Так как $p-value$ = 0.9545 значительно больше $\alpha$ = 0.05, то гипотеза $H_0$ не отвергается на заданном уровне значимости. Значит, можно считать, что гипотеза о равенстве дисперсий генеральных совокупностей *не отвергается* с вероятностью ошибки $a$ = 0.05.
Кроме того, тест выдает выборочное отношение дисперсий двух выборок $F_{наблюдаемое}$ = 0.61399 и его интервальную оценку (она включает 1 и поэтому гипотеза $H_0$ не отвергается).

Чтобы вывести F-критическое, можно воспользоваться встроенной функцией F-распределения. В нашем случае при использовании правосторонней критической области данного критерия нужна вероятность правого хвоста распределения, т.е. P[X ≥x],поэтому задаем это в функции:

```{r}
qf(alpha, 49, 49, lower.tail = FALSE)
```

Получаем $F_{критическое}$ = 1.607289, что превышает $F_{наблюдаемое}$ = 0.61399, следовательно, подтверждаем, что на уровне значимости 0,05 гипотеза о равенстве дисперсий генеральных совокупностей не отвергается.

### 2.2. Тесты на равенство средних

#### 2.2.1. Сравнение среднего совокупности с заданным значением - параметрический тест (t-тест Стьюдента)

Проверка гипотезы о значении генеральной средней $H_o: \mu = \mu_0$ при неизвестной генеральной дисперсии $\sigma^2$ требует предварительной проверки выборки на нормальное распределение.
Проведем тест на равенство средних с помощью стандартной встроенной функции t.test(), которая поддерживает проверку гипотезы о равенстве среднего константе.

Найдем среднее введенной нами ранее выборки х.
Предположим, что выборка x извлечена из нормально распределенной генеральной совокупности $X ∈ N(\mu_x; \sigma_x)$.
Проверим состав нашей переменной с помощью удобной функции проверки целостности данных glimpse из пакета dplyr:

```{r}
library(dplyr)
glimpse(x)
mean(x)
```

Получаем результат, показывающий нам, что это переменная числовая, состоящая из 50 значений, а ее среднее по выборке равно 9.6038.

Допустим, по нормативу среднее значение финансового коэффициента Х должно быть равно 10.Таким образом, нам по имеющейся в нашем распоряжении выборке необходимо проверить нулевую гипотезу $H_0: \mu = \mu_0= 10$:

```{r}
t.test(x, mu = 10)
```

Получаем очень маленькое значение $p-value$ = 3.478e-15, что меньше $\alpha$ = 0.05. Значит, на данном уровне значимости гипотеза о равенстве среднего значения коэффициента 10 *отвергается*. Средняя не соответствует нормативу.

Наблюдаемое значение статистики критерия: t = -11.252

По умолчанию нулевая гипотеза проверяется против двусторонней критической области, одностороннюю альтернативу можно указать, задав alternative = "less" (ЛКО) или "greater" (ПКО). Доверительный интервал для генеральной средней по умолчанию строится в рамках теста с надежностью $0,95$.
$P(9.533038< \mu < 9.674562) = 0.95$. 
Этот интервал не содержит заданное значение $\mu_0= 10$.

В нашем случае при использовании двусторонней критической области данного критерия нужна вероятность $P[|T|\ge t]$, поэтому задаем в функции вероятность $\alpha/2$ (по умолчанию она выдает квантиль уровня $\alpha$, левый хвост, т.е. вероятность $P[T < t]= \alpha$), указываем количество степеней свободы $50-1=49$.

```{r}
qt(alpha/2, 49)
```

Получили $t_{крит}$ = -2.009575. Итак, |$t_{набл}$| > $t_{крит}$, значит, гипотеза $H_0$ отвергается на заданном уровне значимости $\alpha$ = 0.05.

#### 2.2.2. Сравнение среднего выборки с заданным значением - непараметрический тест Вилкоксона

В случае отклонения распределения изучаемой совокупности от нормального для проверки гипотезы о равенстве средней (медианы) определенному значению используется непараметрический критерий Вилкоксона и функция `wilcox.test`, устроенная аналогично функции `t.test`.

```{r}
wilcox.test(x, mu = 10)
```

Получаем $p-value = 7.773e-10$ < 0.05. Значит, гипотеза $H_0: \mu = \mu_0 = 10$ отвергается на уровне значимости $\alpha=0.05$. Средняя не соответствует нормативу.

То же самое сделаем и для $Y$:

```{r}
wilcox.test(y, mu = 91)
```
Получаем $p-value = 7.769e-10$ < 0.05. Значит, гипотеза снова отвергается на уровне значимости $\alpha=0.05$. Средняя не соответствует нормативу.

#### 2.2.3. Сравнение средних двух независимых нормально распределенных совокупностей - параметрический тест (t-тест Стьюдента)

Выполнить этот тест можно с помощью функции t.test(). На входе функция получает две выборки X и Y и два параметра: var.equal и paired. Первый из них отвечает за равенство дисперсий:
var.equal = TRUE означает, что был проведён предыдущий тест и генеральные дисперсии неизвестны, но равны, вследствие чего будет использоваться t-тест Стьюдента. В нашем же случае, когда гипотеза о равенстве дисперсий отверглась, следует поставить var.equal = FALSE, и будет использоваться t-тест Уэлча. Параметр paired = FALSE означает, что выборки независимы. 

```{r}
t.test(x, y, var.equal = FALSE, paired = FALSE)
```

Итак, $p-value = 0.3156$, что больше $\alpha=0.05$. Значит, гипотеза $H_o: \mu_x = \mu_y$ *не отвергается* на уровне значимости $\alpha=0.05$. Средние двух совокупностей с большой долей вероятности равны. На это также указывает и $95$%-ный доверительный интервал их разности $(\mu_x−\mu_y)$, который содержит 0.

$t_{набл}$ = -1.0089

Чтобы вывести $t_{крит}$, воспользуемся функцией квантилей распределения Стьюдента. Количество степеней свободы = 50+50-2 = 98.

```{r}
qt(0.975, 98)
```

$t_{крит}$ = 1.984467 > $t_{набл}$ = -1.0089, значит, гипотеза $H_o: \mu_x = \mu_y$ не отвергается на уровне значимости $\alpha=0.05$.

Визуализировать различия (сходства) между средними можно, например, с помощью  ящичковых диаграмм (boxplots). Для построения этого графика организуем данные в виде таблицы:

```{r}
# Создаем таблицу данных из двух столбцов 
my_data <- data.frame(
                    group = rep(c("x", "y"), each = 50),
                    something = c(x, y)
                      )

print(my_data) # Посмотрим, что получилось
```

Теперь можем построить для двух групп (наших двух переменных X и Y) ящичковые диаграммы.
Для этого понадобится пакет `ggpubr`. Подгрузим его для работы в библиотеку, вызвав из него нужную нам функцию построения ящичковой диаграммы `ggboxplot` и подгрузим его для работы в библиотеку:

```{r, fig.cap= '*Рис. 1. Ящичковые диаграммы (boxplots) для переменных X и Y, построенные с помощью функции `ggboxplot` пакета `ggpubr`*'}
library("ggpubr") 
ggboxplot(my_data, x = "group", y = "something", 
          color = "group", 
          palette = c("#88da8b", "#edb93d"), 
          ylab = "Коэффициент финансового левериджа для 100 фирм", xlab = "Group")
```

Полученный график показывает разброс каждой переменной, и можно сделать вывод, что выборочные средние действительно имеют небольшую разницу.

#### 2.2.4. Сравнение различий двух совокупностей - непараметрический тест Вилкоксона

Будет использоваться функция wilcox.test, устроенная аналогично функции t.test.
Для тех же выборок х и у посмотрим медианы, интерквартильные размахи и тест Вилкоксона для несвязных и связных выборок:

```{r}
median_x = median(x) 
median_x 
median_y = median(y) 
median_y 
IQR_x = IQR(x, na.rm = TRUE) 
IQR_y = IQR(y, na.rm = TRUE) 
IQR_x 
IQR_y 
wilcox.test(x, y) # для несвязных выборок
wilcox.test(x, y, paired = TRUE) # для связных выборок
```
Итак, получаем $p-value = 0.3869$ для несвязных выборок и $p-value = 0.3549$  для связных. Значит, нулевая гипотеза $H_0$ о незначимости различий между совокупностями не отвергается.

### 2.3. Критерии проверки параметров биномиальных распределений
#### 2.3.1.Тест на равенство вероятности успеха в испытании Бернулли определенной константе

*Задача 6 из ДКР. Вариант 8. Номер 5.113. При анализе симметричности монеты выяснилось, что при 400 подбрасываниях «решка» выпала 221 раз. В предположении, генеральная совокупность подчиняется биномиальному закону распределения, проверить на уровне значимости 0,01 следующие гипотезы:*  
*а)  Можно ли считать, что монета симметрична? Или вероятность выпадения «решки» больше, чем «орла»?    (проверить против двух соответствующих конкурирующих гипотез). *   
*б) Сравнить вероятность выпадения «решки» на данной монете с другой, у которой при 360 подбрасываниях «решка» выпала 172 раза.*  

Проверка гипотезы о значении неизвестной генеральной доли (вероятности) биномиально распределенной генеральной совокупности $B(n;p)$ $H_0:p=p_0$ при достаточно больших объемах выборки (по крайней мере, $n>30$ для адекватного применения ЦПТ и нормальной аппроксимации) осуществляется с помощью стандартной встроенной функции с воможностью поправки на непрерывность Йетса (*Yates*):

$n=400$ (большая выборка); $m=221; \alpha = 0.01$;
$$H_0:p=p_0=0.5$$
Конкурирующая гипотеза (монета не симметрична):
$$H_1: p_1 \neq 0.5$$
```{r}
prop.test(221, 400, p = 0.5)
```
Получаем, что $p-value = 0.04036 > 0.01 = \alpha$. Значит, гипотеза $H_0:p=p_0=0.5$ не отвергается на уровне значимости $\alpha = 0.01$, можно сказать, что c большей долей вероятности монета является симметричной.

Надо отметить, что результаты без поправки Йетса не сильно отличаются:

```{r}
prop.test(221, 400, p = 0.5, correct = FALSE)
```

Здесь $p-value = 0.03573 > 0.01 = \alpha$. Аналогично, гипотеза $H_0:p=p_0=0.5$ не отвергается на уровне значимости $\alpha = 0.01$.

В этом случае применима функция с точным биномиальным тестом.

```{r}
binom.test(221, 400, p = 0.5)
```

Получаем, что $p-value = 0.04023 > 0.01 = \alpha$. Значит, гипотеза $H_0:p=p_0=0.5$ снова не отвергается на уровне значимости $\alpha = 0.01$.

Все три теста дали близкие результаты p-value = 0.04 и все меньше уровня значимости $\alpha = 0.01$.

#### 2.3.2. Тест на равенство вероятностей успеха в испытаниях Бернулли для нескольких биномиально распределенных совокупностей

Рассмотрим пункт б) задачи. Имеем:

$n_1 = 400, m_1 = 221, n_2 = 360, m_2 = 172$.

```{r}
prop.test(x = c(221, 172), n = c(400, 360),correct = FALSE)
qchisq(0.99,1)
```

Получаем, $\chi_{набл}^2 = 4.2366 < \chi_{крит}^2=6.634897$, а также $p-value = 0.03956 > \alpha=0.01$, значит, нулевая гипотеза об однородности вероятностей не отвергается с вероятностью ошибки $0.01$. Можно считать монету симметричной.

### 2.4. Критерии согласия эмпирического распределения с теоретическим

#### 2.4.1. Визуализация данных с целью подбора наилучшего теоретического распределения

Построим эмпирическую плотность наших данных о значении исследуемого коэффициента. По ее виду, как и по виду гистограммы можно сделать вывод о предполагаемом теоретическом законе распределения. 

```{r, fig.cap='*Рис. 2. Эмпирическая плотность распределения коэффициента соотношения заёмных и собственных средств по 100 фирмам, построенная с помощью функции `ggdensity` пакета `ggpubr`*'}
volume <- data[[1]] 
ggdensity(volume, 
          main = "Эмпирическая плотность коэффициента соотношения заёмных и собственных средств по 100 фирмам", xlab = "Коэффициент соотношения заёмных и собственных средств")
```

Получаем график плотности, похожий на кривую Гаусса нормального распределения с левосторонней ассиметрией, поэтому проверять гипотезу о принадлежности изучаемой случайной величины нормальному распределению надо в первую очередь.

Построим график типа квантиль-квантиль (Q-Q plot) для проверки соответствия квантилей выборки квантилям нормального распределения. Если точки эмпирического распределения близки к прямой под углом 45 градусов на графике -- это говорит в пользу нормального распределения генеральной совокупности.

```{r, fig.cap='*Рис.3. Квантильный график (`Q-Q plot`) - эмпирическое распределение квантилей коэффициента соотношения заёмных и собственных средств и квантилей нормального распределения, построенный с помощью функции `ggqqplot` пакета `ggpubr`*'}
ggqqplot(volume)
```

Видим, что Q-Q plot (рис. 3) не позволяет выдвинуть гипотезу о нормальном распределении изучаемой совокупности, так как угол наклона близок к 30 градусам. Проведем несколько тестов, чтобы проверить это точнее.

#### 2.4.2. Критерий $\chi^2$ Пирсона

Один из первых и наиболее распространенных критериев согласия, применяемый как для дискретных, так и для непрерывных распределений при условии достаточно большого объема выборки (не менее 50 наблюдений). Основан на сравнении эмпирических и теоретических частот предполагаемого распределения. Как свидетельствуют результаты научных исследований, показывает достаточно неплохие результаты по сравнению с другими критериями, при этом очень прост и понятен в реализации.

Воспользуемся пакетом `nortest` и функцией `pearson.test`:

```{r}
library(nortest)
pearson.test(volume)
```

Значение $p-value = 0.2811 > 0.05 = \alpha$, гипотеза $H_o$ о нормальности распределения не отвергается на данном уровне значимости.

#### 2.4.3. Критерий Андерсона-Дарлинга (AD test)

Проведем тест Андерсона-Дарлинга при помощи функции `ad.test()` из пакета `nortest`: 

```{r}
library('nortest')
ad.test(volume)
```

Получаем $p-value = 0.04536 < 0.05 = \alpha$, гипотеза о нормальном распределении отвергается с вероятностью ошибки $\alpha = 0.05$*. 

#### 2.4.4. Критерий Лиллиефорса (Lilliefors(Kolmogorov-Smirnov))

Этот критерий является модификацией теста Колмогорова- Смирнова, его можно проверить при помощи функции `lillie.test()` из пакета `nortest`.

```{r}
lillie.test(volume)
```

Итак $p-value = 0.06008 > 0.05 = \alpha$, поэтому гипотеза о нормальности распределения не отвергается с вероятностью ошибки $\alpha = 0.05$.

#### 2.4.5. Критерий Жарка-Бера (Jarque-Bera test)

Тест Жарка-Берра (Carlos Jarque and Anil K. Bera) используется для проверки нормальности распределения величины. Разработаны две модификации теста, которые позволяют проверить классическим (`robust = FALSE`) или робастым методом (`robust = TRUE`). Установим пакет `DescTools` и применим функцию `JarqueBeraTest`:

```{r}
library('DescTools')
JarqueBeraTest(volume, robust = FALSE)
JarqueBeraTest(volume, robust = TRUE)
```

В обоих случаях `р-value` > $0.05$ (`p-value` = $0.605$ для `robust = FALSE` и `p-value` = $0.7043$ для `robust = TRUE`), что говорит о том, что гипотеза о нормальном распределении не отвергается на уровне значимости $\alpha = 0.05$.

#### 2.4.6. Д'Агустино тест (D'Agostino's K2 test)

Еще один тест на критерий согласия проведем при помощи функции `dagoTest` из пакета `fBasics`:

```{r}
library('fBasics')
dagoTest(volume)
```

Получаем, что все p-значения больше 0.05, значит, гипотеза о нормальности не отвергается на уровне значимости $\alpha = 0.05$.


Таким образом, большинство критериев не отвергают гипотезу о нормальном распределении данных, несмотря на достаточно ярко выраженную левостороннюю асимметрию.